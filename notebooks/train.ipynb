{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q55pnAz0iXp0"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpZwRS0qGpSk"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import requests\n",
        "import zipfile\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y53qWpadjTsU"
      },
      "source": [
        "# clone the git repository and set it as the working directory\n",
        "! git clone https://github.com/martin-marek/parking-space-occupancy\n",
        "os.chdir('parking-space-occupancy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWtVcExICel"
      },
      "source": [
        "# download the dataset\n",
        "if not os.path.exists('dataset/data'):\n",
        "    r = requests.get(\"https://pub-e8bbdcbe8f6243b2a9933704a9b1d8bc.r2.dev/parking%2Frois_gopro.zip\")\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall('dataset/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W-TJxl12O7P"
      },
      "source": [
        "# set device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LhmBQXj3O5w"
      },
      "source": [
        "# import dataset, models, and training utils.\n",
        "from dataset import acpds\n",
        "from utils.engine import train_model\n",
        "from models.rcnn import RCNN\n",
        "from models.faster_rcnn_fpn import FasterRCNN_FPN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojkcnXc4HKlM"
      },
      "source": [
        "# load dataset\n",
        "train_ds, valid_ds, test_ds = acpds.create_datasets('dataset/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeyNiElD2ahL",
        "outputId": "204ae128-bcdf-4be0-8e4b-59786d5b1ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train model\n",
        "model = RCNN()\n",
        "out_dir = 'out_dir'\n",
        "train_model(model, train_ds, valid_ds, test_ds, out_dir, device, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 175MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   1 -- train acc: 0.8628 -- valid acc.: 0.9301 -- 77 sec\n",
            "epoch   2 -- train acc: 0.9341 -- valid acc.: 0.9470 -- 57 sec\n",
            "epoch   3 -- train acc: 0.9422 -- valid acc.: 0.9165 -- 57 sec\n",
            "epoch   4 -- train acc: 0.9487 -- valid acc.: 0.9575 -- 57 sec\n",
            "epoch   5 -- train acc: 0.9533 -- valid acc.: 0.9695 -- 57 sec\n",
            "epoch   6 -- train acc: 0.9686 -- valid acc.: 0.9559 -- 57 sec\n",
            "epoch   7 -- train acc: 0.9596 -- valid acc.: 0.9653 -- 59 sec\n",
            "epoch   8 -- train acc: 0.9611 -- valid acc.: 0.9690 -- 58 sec\n",
            "epoch   9 -- train acc: 0.9746 -- valid acc.: 0.9685 -- 57 sec\n",
            "epoch  10 -- train acc: 0.9621 -- valid acc.: 0.9601 -- 57 sec\n",
            "epoch  11 -- train acc: 0.9638 -- valid acc.: 0.9716 -- 57 sec\n",
            "epoch  12 -- train acc: 0.9781 -- valid acc.: 0.9664 -- 57 sec\n",
            "epoch  13 -- train acc: 0.9749 -- valid acc.: 0.9748 -- 57 sec\n",
            "epoch  14 -- train acc: 0.9788 -- valid acc.: 0.9790 -- 57 sec\n",
            "epoch  15 -- train acc: 0.9786 -- valid acc.: 0.9800 -- 57 sec\n",
            "epoch  16 -- train acc: 0.9753 -- valid acc.: 0.9653 -- 57 sec\n",
            "epoch  17 -- train acc: 0.9805 -- valid acc.: 0.9774 -- 57 sec\n",
            "epoch  18 -- train acc: 0.9802 -- valid acc.: 0.9795 -- 57 sec\n",
            "epoch  19 -- train acc: 0.9795 -- valid acc.: 0.9769 -- 57 sec\n",
            "epoch  20 -- train acc: 0.9792 -- valid acc.: 0.9638 -- 57 sec\n",
            "epoch  21 -- train acc: 0.9801 -- valid acc.: 0.9259 -- 57 sec\n",
            "epoch  22 -- train acc: 0.9751 -- valid acc.: 0.9485 -- 57 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU04SII65VNZ"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import namedtuple\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the training logs\n",
        "logs_dir = 'training_output'\n",
        "if not os.path.exists(logs_dir):\n",
        "    r = requests.get(\"https://pub-e8bbdcbe8f6243b2a9933704a9b1d8bc.r2.dev/parking%2Fpaper_training_output.zip\")\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(logs_dir)"
      ],
      "metadata": {
        "id": "U42mlnvWMWhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'FasterRCNN_FPN_800_square'\n",
        "train_log = pd.read_csv(f'{logs_dir}/{model_name}_0/train_log.csv')\n",
        "va = train_log.valid_accuracy.tolist()\n",
        "plt.plot(va, label=model_name)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation acc. (%)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rdqqEvLMMXlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dicts with model validation and test accuracies\n",
        "va_dict = defaultdict(list)\n",
        "ta_dict = defaultdict(list)\n",
        "\n",
        "# iterate through model directories\n",
        "for model_dir in sorted(glob(f'{logs_dir}/*')):\n",
        "\n",
        "    # get model id based on model directory\n",
        "    model_id = model_dir.split('/')[-1]\n",
        "\n",
        "    # split model_id into model_name and training_iter\n",
        "    model_name, _ = model_id.rsplit('_', 1)\n",
        "\n",
        "    # read validation accuracy from training logs\n",
        "    train_log = pd.read_csv(f'{model_dir}/train_log.csv')\n",
        "    va = train_log.valid_accuracy.tolist()\n",
        "\n",
        "    # append logs if they're the first logs of the given model\n",
        "    # or if they're of the same length as the previous logs\n",
        "    # (avoid storing logs of a model that hasn't finished trainig yet)\n",
        "    if len(va_dict[model_name]) == 0 or len(va_dict[model_name][0]) == len(va):\n",
        "        # read test accuracy from test logs\n",
        "        with open(f'{model_dir}/test_logs.json') as f:\n",
        "            ta = json.load(f)['accuracy']\n",
        "\n",
        "        va_dict[model_name] += [va]\n",
        "        ta_dict[model_name] += [ta]\n",
        "\n",
        "# compute accuracy mean and SE for each model\n",
        "Logs = namedtuple('Logs', ['va_mean', 'va_se', 'ta_mean', 'ta_se'])\n",
        "logs = {}\n",
        "for k, v in va_dict.items():\n",
        "    # print number of training iters for each model\n",
        "    print(f'{k}: {len(v)}')\n",
        "\n",
        "    # calculate the mean and standard error of valid. accuracy\n",
        "    va = np.array(v)\n",
        "    # va = np.array([ma(x, 10) for x in va])\n",
        "    va_mean = np.mean(va, 0)\n",
        "    va_se = np.std(va, 0) / np.sqrt(va.shape[0])\n",
        "\n",
        "    # calculate the mean and standard error of test accuracy\n",
        "    ta = np.array(ta_dict[k])\n",
        "    ta_mean = np.mean(ta)\n",
        "    ta_se = np.std(ta) / np.sqrt(len(ta))\n",
        "\n",
        "    # save validation and test logs\n",
        "    logs[k] = Logs(va_mean, va_se, ta_mean, ta_se)"
      ],
      "metadata": {
        "id": "dR4kaWb3Mb7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ma(x, w=10):\n",
        "    \"\"\"Moving average.\"\"\"\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ],
      "metadata": {
        "id": "zTTUZk-5MeYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=[12, 8])\n",
        "for k, v in logs.items():\n",
        "    epochs = np.arange(len(v.va_mean))\n",
        "    plt.plot(epochs, v.va_mean, label=k, linewidth=2)\n",
        "    plt.fill_between(epochs, v.va_mean-v.va_se, v.va_mean+v.va_se, alpha=0.5)\n",
        "ax.legend()\n",
        "ax.set_ylim([0.925, 0.99])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1gTULCqBMiDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with model accuracies\n",
        "df = pd.DataFrame(columns=['Architecture', 'Pooling', 'Resolution', 'Valid. accuracy [\\%]', 'Test accuracy [\\%]'])\n",
        "for i, (k, v) in enumerate(logs.items()):\n",
        "    model_name, res, pooling = k.rsplit('_', 2)\n",
        "    model_name = {'RCNN': 'R-CNN', 'FasterRCNN_FPN': 'Faster R-CNN FPN'}[model_name]\n",
        "    pooling = {'qdrl': 'quadrilateral', 'square': 'square'}[pooling]\n",
        "    va_str = f'{100*v.va_mean[-1]:.2f} $\\pm$ {100*v.va_se[-1]:.2f}' # valid. accuracy\n",
        "    ta_str = f'{100*v.ta_mean:.2f} $\\pm$ {100*v.ta_se:.2f}' # test accuracy\n",
        "    df.loc[i] = [model_name, pooling, res, va_str, ta_str]"
      ],
      "metadata": {
        "id": "xJ2H1kVzMkzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the dataframe\n",
        "df['Resolution'] = df['Resolution'].astype(int)\n",
        "df = df.sort_values(['Architecture', 'Pooling', 'Resolution'], ascending=[True, False, False])\n",
        "df"
      ],
      "metadata": {
        "id": "vu8p7o4nMoXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}